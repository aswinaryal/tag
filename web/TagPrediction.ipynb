{
 "metadata": {
  "name": "",
  "signature": "sha256:719747dc09824655da4304a25034288207fc33a95e725e4d139bdab3e88bb166"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Predicting Tags for StackExchange Posts\n",
      "\n",
      "by En-Hsin Peng. A 2015 Data Incubator Project.\n",
      "\n",
      "##Overview and Motivation\n",
      "\n",
      "\n",
      "The dataset is obtained from <a href=\"https://www.kaggle.com/c/facebook-recruiting-iii-keyword-extraction/\">Kaggle competition</a>. It contains\n",
      "<ul>\n",
      "<li>6 million posts from StackExchange sites (e.g., StackOverflow, MathOverflow, AskUbuntu)</li>\n",
      "<li>1-2 million unique words, symbols, phrases</li>\n",
      "<li>42000 different tags</li>\n",
      "<li>Each post has 1 to 5 tags</li>\n",
      "</ul>\n",
      "\n",
      "The goal is to predict each question's tags using its text and title.\n",
      "\n",
      "#Approach\n",
      "<ul>\n",
      "<li>Remove duplicated examples from train set. This reduced the training set to 4 million posts.</li>\n",
      "<li>Clean the data.</li>\n",
      "<li>Build tag-word co-occurrence matrix.</li>\n",
      "<li>Logistic regression with SGD for the first 1000 tags.</li>\n",
      "</ul>\n",
      "\n",
      "#### Evaluation Metrics\n",
      "\n",
      "Precision $p$: the ratio of true positive to all predicted positive (true positive + false positive)\n",
      "\n",
      "Recall $r$: the ratio of true positive to all actual positives (true positive + false negative)\n",
      "\n",
      "F1 score:  $\\frac{2\\,p\\,r}{p+r}$\n",
      "\n",
      "For multi-tag prediction, the performance is evaluated by a <a href=\"https://www.kaggle.com/wiki/MeanFScore\">mean F1 score</a>.\n",
      "\n",
      "\n",
      "#Result\n",
      "<ul>\n",
      "<li>Single tag accuracy = 0.728 on unseen non-duplicated 40,000 examples.</li>\n",
      "<li>Multi-tag prediction mean F1 score = 0.490. If adding 108.7% more known data to this set to mimic the actual Kaggle's test set, which has many duplicate examples from the training set, the F1 score is inflated to 0.756.</li>\n",
      "</ul>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Reference\n",
      "<ul>\n",
      "<li>Kaggle <a href=\"https://www.kaggle.com/c/facebook-recruiting-iii-keyword-extraction/\">Facebook Recruiting III - Keyword Extraction</a></li>\n",
      "<li>James Hong & Michael Fang <a href=\"http://cs229.stanford.edu/proj2013/FangHong-Keyword%20Extraction%20and%20Semantic%20Tag%20Prediction.pdf\">Keyword Extraction and Semantic Tag Prediction</a></li>\n",
      "<li>Chintan Parikh <a href:\"http://cs229.stanford.edu/proj2013/Parikh-IdentifyTagsFromMillionsOfTextQuestion.pdf\">Identifying Tags from millions of text question</a></li>\n",
      "<li>Yaser Martinez Palenzuela <a href=\"http://yasermartinez.com/blog/posts/stack-exchange-tag-predictions.html\">Stack Exchange tag predictions</a></li>\n",
      "<li>scikit-learn <a href=\"http://scikit-learn.org/stable/auto_examples/applications/plot_out_of_core_classification.html\">Out-of-core classification of text documents</a></li>\n",
      "</ul>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}